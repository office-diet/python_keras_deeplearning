{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "import tensorflow as tf\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    seq_model = Sequential()\n",
    "    seq_model.add(Dense(32, activation=\"relu\", input_shape=(64, )))\n",
    "    seq_model.add(Dense(32, activation=\"relu\"))\n",
    "    seq_model.add(Dense(10, activation=\"softmax\"))\n",
    "\n",
    "    input_tensor = Input(shape=(64, ))\n",
    "    x = Dense(32, activation=\"relu\")(input_tensor)\n",
    "    x = Dense(32, activation=\"relu\")(x)\n",
    "    output_tensor = Dense(10, activation=\"softmax\")(x)\n",
    "\n",
    "    model = Model(input_tensor, output_tensor)\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 32)                2080      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 3,466\n",
      "Trainable params: 3,466\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    seq_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 1ms/step - loss: 11.8099\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 11.9714\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 12.7313\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 14.1545\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 16.0890\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 18.0590\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 20.5751\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 0s 999us/step - loss: 23.7546\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 27.2625\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 0s 1ms/step - loss: 31.4116\n",
      "32/32 [==============================] - 0s 645us/step - loss: 34.8427\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")\n",
    "    \n",
    "    x_train = np.random.random((1000, 64))\n",
    "    y_train = np.random.random((1000, 10))\n",
    "    \n",
    "    model.fit(x_train, y_train, epochs=10, batch_size=128)\n",
    "    model.evaluate(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "question (InputLayer)           [(None, None)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, None, 64)     640000      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 32)     320000      question[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           12416       embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 16)           3136        embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 48)           0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 500)          24500       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 1,000,052\n",
      "Trainable params: 1,000,052\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding, LSTM, concatenate\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "text_vocabulary_size = 10000\n",
    "question_vocabulary_size = 10000\n",
    "answer_vocabulary_size = 500\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    text_input = Input(shape=(None, ), dtype=\"int32\", name=\"text\")\n",
    "    embedded_text = Embedding(text_vocabulary_size, 64)(text_input)\n",
    "    encoded_text = LSTM(32)(embedded_text)\n",
    "\n",
    "    question_input = Input(shape=(None, ), dtype=\"int32\", name=\"question\")\n",
    "    embedded_question = Embedding(question_vocabulary_size, 32)(question_input)\n",
    "    encoded_question = LSTM(16)(embedded_question)\n",
    "\n",
    "    concatenated = concatenate([encoded_text, encoded_question], axis=-1)\n",
    "\n",
    "    answer = Dense(answer_vocabulary_size, activation=\"softmax\")(concatenated)\n",
    "\n",
    "    model = Model([text_input, question_input], answer)\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "    model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 6.2944 - acc: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 6.1734 - acc: 0.0030\n",
      "Epoch 3/10\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 6.0996 - acc: 0.0030\n",
      "Epoch 4/10\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 6.0178 - acc: 0.0050\n",
      "Epoch 5/10\n",
      "8/8 [==============================] - 1s 83ms/step - loss: 5.9151 - acc: 0.0070\n",
      "Epoch 6/10\n",
      "8/8 [==============================] - 1s 84ms/step - loss: 5.8267 - acc: 0.0160\n",
      "Epoch 7/10\n",
      "8/8 [==============================] - 1s 95ms/step - loss: 5.7550 - acc: 0.0210\n",
      "Epoch 8/10\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 5.6762 - acc: 0.0230\n",
      "Epoch 9/10\n",
      "8/8 [==============================] - 1s 78ms/step - loss: 5.6048 - acc: 0.0250\n",
      "Epoch 10/10\n",
      "8/8 [==============================] - 1s 79ms/step - loss: 5.5509 - acc: 0.0220\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "num_samples = 1000\n",
    "max_length = 100\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    text = np.random.randint(1, text_vocabulary_size, size=(num_samples, max_length))\n",
    "    question = np.random.randint(1, question_vocabulary_size, size=(num_samples, max_length))\n",
    "\n",
    "    answers = np.zeros(shape=(num_samples, answer_vocabulary_size))\n",
    "    indices = np.random.randint(0, answer_vocabulary_size, size=num_samples)\n",
    "    for i, x in enumerate(answers):\n",
    "        x[indices[i]] = 1\n",
    "\n",
    "    model.fit([text, question], answers, epochs=10, batch_size=128)\n",
    "#     model.fit({\"text\": text, \"question\": question}, answers, epochs=10, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalMaxPooling1D, Dense, Embedding\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "vocabulary_size = 50000\n",
    "num_income_groups = 10\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    posts_input = Input(shape=(None, ), dtype=\"int32\", name=\"posts\")\n",
    "    embedded_posts = Embedding(256, vocabulary_size)(posts_input)\n",
    "    x = Conv1D(128, 5, activation=\"relu\")(embedded_posts)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(256, 5, activation=\"relu\")(x)\n",
    "    x = Conv1D(256, 5, activation=\"relu\")(x)\n",
    "    x = MaxPooling1D(5)(x)\n",
    "    x = Conv1D(256, 5, activation=\"relu\")(x)\n",
    "    x = Conv1D(256, 5, activation=\"relu\")(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(128, activation=\"relu\")(x)\n",
    "\n",
    "    age_prediction = Dense(1, name=\"age\")(x)\n",
    "    income_prediction = Dense(num_income_groups, activation=\"softmax\", name=\"income\")(x)\n",
    "    gender_prediction = Dense(1, activation=\"sigmoid\", name=\"gender\")(x)\n",
    "\n",
    "    model = Model(posts_input, [age_prediction, income_prediction, gender_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    model.compile(optimizer=\"rmsprop\", loss=[\"mse\", \"categorical_crossentropy\", \"binary_crossentropy\"])\n",
    "    model.compile(optimizer=\"rmsprop\", loss={\"age\": \"mse\", \"income\": \"categorical_crossentropy\", \"gender\": \"binary_crossentropy\"})\n",
    "    \n",
    "    model.compile(optimizer=\"rmsprop\", loss=[\"mse\", \"categorical_crossentropy\", \"binary_crossentropy\"], loss_weights=[0.25, 1., 10.])\n",
    "    model.compile(optimizer=\"rmsprop\", loss={\"age\": \"mse\", \"income\": \"categorical_crossentropy\", \"gender\": \"binary_crossentropy\"},\n",
    "                 loss_weights={\"age\": 0.25, \"income\": 1., \"gender\": 10.})\n",
    "    \n",
    "    model.fit(posts, [age_targets, income_targets, gender_targets], epochs=10, batch_size=64)\n",
    "    model.fit(posts, {\"age\": age_targets, \"income\": income_targets, \"gender\": gender_targets}, epochs=10, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, concatenate\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    branch_a = Conv2D(128, 1, activation=\"relu\", strides=2)(x)\n",
    "\n",
    "    branch_b = Conv2D(128, 1, activation=\"relu\")(x)\n",
    "    branch_b = Conv2D(128, 3, activation=\"relu\", strides=2)(branch_b)\n",
    "\n",
    "    branch_c = AveragePooling2D(3, strides=2)(x)\n",
    "    branch_c = Conv2D(128, 3, activation=\"relu\")(branch_c)\n",
    "\n",
    "    branch_d = Conv2D(128, 1, activation=\"relu\")(x)\n",
    "    branch_d = Conv2D(128, 3, activation=\"relu\")(branch_d)\n",
    "    branch_d = Conv2D(128, 3, activation=\"relu\", strides=2)(branch_d)\n",
    "\n",
    "    output= concatenate([branch_a, branch_b, branch_c, branch_d], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "y = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(y)\n",
    "y = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(y)\n",
    "y = layers.add([y, x])\n",
    "\n",
    "x = ...\n",
    "y = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(x)\n",
    "y = layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\")(y)\n",
    "y = layers.MaxPooling2D(2, strides=2)(y)\n",
    "\n",
    "residual = layers.Conv2D(128, 1, strides=2, padding=\"same\")(x)\n",
    "\n",
    "y = layers.add([y, residual])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    lstm = layers.LSTM(32)\n",
    "\n",
    "    left_input = Input(shape=(None, 128))\n",
    "    left_output = lstm(left_input)\n",
    "\n",
    "    right_input = Input(shape=(None, 128))\n",
    "    right_output = lstm(left_input)\n",
    "\n",
    "    merged = layers.concatenate([left_output, right_output], axis=-1)\n",
    "    predictions = layers.Dense(1, activation=\"sigmoid\")(merge)\n",
    "\n",
    "    model = Model([left_input, right_input], predictions)\n",
    "    model.fit([left_data, right_data], targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras import Input\n",
    "\n",
    "xception_base = applications.Xception(weights=None, include_top=False)\n",
    "\n",
    "left_input = Input(shape=(250, 250, 3))\n",
    "right_input = Input(shape=(250, 250, 3))\n",
    "\n",
    "left_features = xception_base(letf_input)\n",
    "right_features = xception_base(right_input)\n",
    "\n",
    "merged_features = layers.concatenate([left_features, right_features], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = {\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor=\"val_acc\",\n",
    "        patience=1,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckPoint(\n",
    "        filepath=\"my_model.h5\",\n",
    "        monitor=\"val_loss\",\n",
    "        save_best_only=True,\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras\n",
    "import numpy as np\n",
    "\n",
    "class ActivationLogger(keras.callbaks):\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "        layer_outputs = [layer.output for layer in model.layers]\n",
    "        self.activations_model = keras.models.Model(model.input, layer_outputs)\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if self.validation_data is None:\n",
    "            raise RuntimeError(\"Requires validation_data.\")\n",
    "            \n",
    "            validation_sample = self.validation_data[0][0:1]\n",
    "            activations = self.activations_model.predict(validation_sample)\n",
    "            \n",
    "            f = open(\"activation_at_epoch_\" + str(epoch) + \".npz\", \"w\")\n",
    "            np.save(f, activations)\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embed (Embedding)            (None, 500, 128)          256000    \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 494, 32)           28704     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 98, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 92, 32)            7200      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 291,937\n",
      "Trainable params: 291,937\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_features = 2000\n",
    "max_len = 500\n",
    "\n",
    "import tensorflow as tf\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    (x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "    x_train = pad_sequences(x_train)\n",
    "    x_test = pad_sequences(x_test)\n",
    "\n",
    "    model = keras.models.Sequential()\n",
    "    model.add(layers.Embedding(max_features, 128, input_length=max_len, name=\"embed\"))\n",
    "\n",
    "    model.add(layers.Conv1D(32, 7, activation=\"relu\"))\n",
    "    model.add(layers.MaxPooling1D(5))\n",
    "    model.add(layers.Conv1D(32, 7, activation=\"relu\"))\n",
    "    model.add(layers.GlobalMaxPooling1D())\n",
    "    model.add(layers.Dense(1))\n",
    "    model.summary()\n",
    "    model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    callbacks = [\n",
    "        keras.callbacks.TensorBoard(\n",
    "            log_dir=\"my_log_dir\", histogram_freq=1, embeddings_freq=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    history = model.fit(x_train, y_train, epochs=20, batch_size=128, validation_split=0.2, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "with tf.device(\"/cpu:0\"):\n",
    "    plot_model(model, to_file=\"model.png\")\n",
    "    plot_model(model, show_shapes=True, to_file=\"model_shape.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import \n",
    "\n",
    "height = 64\n",
    "width = 64\n",
    "channels = 3\n",
    "num_classes = 10\n",
    "\n",
    "model = Sequential()\n",
    "model.add(SeparableConv2D(32, 3, activation=\"relu\", input_shape=(height, width, channels, )))\n",
    "model.add(SeparableConv2D(64, 3, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(SeparableConv2D(64, 3, activation=\"relu\"))\n",
    "model.add(SeparableConv2D(128, 3, activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2))\n",
    "\n",
    "model.add(SeparableConv2D(64, 3, activation=\"relu\"))\n",
    "model.add(SeparableConv2D(128, 3, activation=\"relu\"))\n",
    "model.add(GlobalAveragePooling2D())\n",
    "\n",
    "model.add(Dense(32, activation=\"relu\"))\n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
